# -*- coding: utf-8 -*-
"""PML_HPO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ap_WaQslMUdIaGSfZBgipQYrTvq3d_cI
"""

#https://scikit-optimize.github.io/stable/auto_examples/sklearn-gridsearchcv-replacement.html#sphx-glr-auto-examples-sklearn-gridsearchcv-replacement-py
#https://skopt.readthedocs.io/en/stable/install.html
#https://tex.stackexchange.com/questions/480652/prevent-table-from-going-off-page-how
#install and import packages
#!pip install --upgrade scikit-learn
#!pip install pandas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn

#suppress warnings about class imbalances
import warnings
warnings.filterwarnings("ignore")

#import models, packages
from sklearn import linear_model, ensemble
from sklearn.model_selection import cross_val_score
from sklearn import model_selection
import numpy

#!pip install scikit-optimize
import skopt
from skopt.space import Real, Categorical, Integer
from skopt import BayesSearchCV

#import grid search and cross_validate
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_validate

#print python version for report
#!python ‐‐version
import sys; print(sys.version)

#read and display data
data = pd.read_csv("winequality-red.csv", sep = ";")
pd.set_option('display.width', None)
pd.set_option('max_colwidth', None)
#display information about dataset for report
data.columns
print(data.groupby(['quality']).count())

#split into features/target
x = data.drop(columns = ['quality'])
#attemptd normalization at one point but this step yielded lower performance
#x_norm = sklearn.preprocessing.normalize(x, axis=0)
#https://www.howtogeek.com/778790/how-to-copy-files-and-directories-in-linux-terminal/
#https://linuxize.com/post/remove-directory-linux/
#https://askubuntu.com/questions/703698/how-do-i-navigate-up-one-directory-from-the-terminal
#https://note.nkmk.me/en/python-package-version/
#https://stackoverflow.com/questions/10214827/find-which-version-of-package-is-installed-with-pip
y = data['quality']
print("this is the one w 10 iter, 10 pts, 10 jobs, BayesSearchCV inside cross_validate call")
ridge_opt = BayesSearchCV(linear_model.RidgeClassifier(),
    {
    "alpha": Real(1.0, 5.0, prior='log-uniform'),
    "tol": Real(0.0001, 0.1, prior='log-uniform'),
    "solver": Categorical(["svd", "cholesky", "lsqr", "sparse_cg"]),
    "max_iter": Integer(100, 100000, prior='log-uniform'),
    },
    n_iter = 50,
    n_jobs = 10, 
    n_points = 10,
     random_state=0,
     scoring = "balanced_accuracy"
)

bagging_opt = BayesSearchCV(ensemble.BaggingClassifier(),
                {"n_estimators" : Integer(100, 10000, prior = 'log-uniform'),
               "max_samples" : Real(0.01, 1.0, prior='log-uniform'),
                "max_features" : Real(0.01, 1.0, prior='log-uniform'),
                },
         n_iter = 50,
    n_jobs = 10, 
    n_points = 10,
        random_state=0,
        scoring = "balanced_accuracy"

)

rf_opt = BayesSearchCV(ensemble.RandomForestClassifier(),
        {
    "n_estimators" : Integer(100, 10000, prior = 'log-uniform'),
    "criterion" : Categorical(["gini", "entropy", "log_loss"]),
    "max_depth" : Integer(2, 10, prior='log-uniform')
        },
         n_iter = 50,
    n_jobs = 10, 
    n_points = 10, 
        random_state=0,
        scoring = "balanced_accuracy"
)

def nested_resampling_bayesian(optimizer, x, y):
    cv_results = cross_validate(
        optimizer, x, y, return_estimator=True, scoring = "balanced_accuracy", n_jobs = -1
    )
    
    cv_results_df = pd.DataFrame(cv_results)
    print(cv_results_df)
    cv_test_scores = cv_results_df["test_score"]
    max_idx  = cv_results_df['test_score'].idxmax()
    print(cv_results["estimator"][max_idx].best_estimator_)
    #display results
    print(
    "Generalization score with hyperparameters tuning:\n"
            f"{cv_test_scores.mean():.3f} ± {cv_test_scores.std():.3f}"
    )
    print(cv_results_df.loc[cv_results_df['test_score'].idxmax()])

nested_resampling_bayesian(ridge_opt, x, y)

nested_resampling_bayesian(bagging_opt, x, y)

nested_resampling_bayesian(rf_opt, x, y)

